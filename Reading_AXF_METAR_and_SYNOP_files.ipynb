{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from Utilities.dynarray import DynamicRecArray as recarray\n",
    "from Utilities.metutils import convert\n",
    "\n",
    "# Import widgets for interactive notebook\n",
    "from ipywidgets import interact, fixed, interactive\n",
    "from IPython.html import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data formats for reading csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parseTime(datestr, timestr):\n",
    "    return datetime.strptime(\"{0} {1}\".format(datestr, timestr), \"%Y%m%d %H%M\")\n",
    "\n",
    "METAR_DTYPE=[(\"stnWMO\", '|S5'), (\"stnCode\", \"|S4\"), (\"dtDate\", \"|S16\"), (\"dtTime\", \"|S8\"), \n",
    "       (\"stnLat\", \"f8\"), (\"stnLon\", \"f8\"), (\"winddir\", \"f8\"), (\"windspeed\", \"f8\"), \n",
    "       (\"tempDB\", \"f8\"), (\"dewpt\", \"f8\"), (\"QNH\", \"f8\"), (\"RF9am\", \"f8\"), (\"RF10min\", \"f8\"),\n",
    "       (\"vis\", \"f8\"), (\"Avis\", \"f8\"), (\"gust\", \"f8\")]\n",
    "# METAR_DTYPE=[ (\"dtDateTime\", '|S5'),(\"stnWMO\", '|S5'), (\"stnCode\", \"|S4\"), \n",
    "#        (\"stnLat\", \"f8\"), (\"stnLon\", \"f8\"), (\"winddir\", \"f8\"), (\"windspeed\", \"f8\"), \n",
    "#        (\"tempDB\", \"f8\"), (\"dewpt\", \"f8\"), (\"QNH\", \"f8\"), (\"RF9am\", \"f8\"), (\"RF10min\", \"f8\"),\n",
    "#        (\"vis\", \"f8\"), (\"Avis\", \"f8\"), (\"gust\", \"f8\")]\n",
    "METAR_NAMES = [field[0] for field in METAR_DTYPE]\n",
    "METAR_NAMES_MOD = ['stnWMO', 'dtDateTime', 'stnCode',  'stnLat', 'stnLon', 'winddir', 'windspeed', 'tempDB', \n",
    "                   'dewpt', 'QNH', 'RF9am', 'RF10min', 'vis', 'Avis', 'gust']\n",
    "METAR_COLS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "METAR_CONV = {'stnCode': lambda s: s.strip('\"'),\n",
    "              'windspeed': lambda s: convert(s, \"kts\", \"mps\"),\n",
    "              'gust': lambda s: convert(s, \"kts\", \"mps\")}\n",
    "\n",
    "SYNOP_DTYPE = [('stnWMO', '|S5'), ('stnName', '|S31'), ('stnCode', '|S4'), ('dtDate', '|S16'), \n",
    "               ('dtTime', '|S16'), ('stnLat', 'f8'), ('stnLon', 'f8'), ('winddir', 'f8'), \n",
    "               ('windspeed', 'f8'), ('vis', 'f8'), ('presentWxCode', '|S8'), ('pastWxCode', 'f8'),\n",
    "               ('mslp', 'f8'), ('tempDB', 'f8'), ('dewpt', 'f8')]\n",
    "SYNOP_NAMES = [field[0] for field in SYNOP_DTYPE]\n",
    "SYNOP_NAMES_MOD = ['stnWMO', 'dtDateTime', 'stnName', 'stnCode', 'stnLat', 'stnLon', 'winddir', \n",
    "                   'windspeed', 'vis', 'presentWxCode', 'pastWxCode', 'mslp', 'tempDB', 'dewpt']\n",
    "SYNOP_COLS = [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 16, 21, 22]\n",
    "SYNOP_CONV = {'stnName': lambda s: s.strip('\"').rstrip(' '),\n",
    "              'stnCode': lambda s: s.strip('\"').rstrip(' '),\n",
    "              'presentWxCode': lambda s: s.strip('\"').rstrip(' ')}\n",
    "\n",
    "inputPath = \"B:/CHARS/B_Wind/data/raw/obs/axf\"\n",
    "outputPath = \"B:/CHARS/B_Wind/data/derived/obs/metar/TCDebbie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Debbie_stns = ['94294', '94356', '94360', '94365', '94366', '19367', '94368', '94369', \n",
    "               '94371', '95295', '95297', '95367']\n",
    "Debbie_stns_dict = {94294:'Townsville Amo', 94356:'Charters Towers Airport', 94360:'Collinsville', \n",
    "                94365:'Proserpine Airport', 94366:'Bowen Airport', 19367:'Mackay Mo', 94368:'Hamilton Island', \n",
    "                94369:'St Lawrence Post Office', 94371:'Creal Reef', 95295:'Ayr Dpi Research Station', \n",
    "                95297:'Hook Reef Aws', 95367:'Mackay Airport'}\n",
    "# Stations in the area of TC Debbie's landfall. Taken from ArcGIS map. Approximately cover the extent of the TCRM\n",
    "# genreated wind field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metarbasename = {\"IDY03101.2017032*.axf\":\"3101\", \"IDY03100.2017032*.axf\":\"3100\"}\n",
    "\n",
    "for db in metarbasename:\n",
    "    metardata = {}\n",
    "\n",
    "    filelist = glob(pjoin(inputPath, db))\n",
    "    for f in filelist:\n",
    "        arr = pd.read_csv(f, skiprows = 2, header=None, usecols=METAR_COLS, names = METAR_NAMES, \n",
    "                          dtype = METAR_DTYPE, parse_dates = {'dtDateTime':[2, 3]}, na_values = -9999.0)\n",
    "        cols = arr.columns.tolist()\n",
    "        cols[0], cols[1] = cols[1], cols[0]\n",
    "        arr = arr[cols]\n",
    "        arr = arr.to_records()\n",
    "        for i in range(len(arr)):\n",
    "            key = \"{0}\".format(arr[\"stnWMO\"][i])\n",
    "            if metardata.has_key(key):\n",
    "                metardata[key] = np.append(metardata[key], arr[i])\n",
    "            else:\n",
    "                metardata[key] = recarray(METAR_DTYPE)\n",
    "                metardata[key] = arr[i]\n",
    "    metarfmt = ['%s', '%s', '%s', '%6.2f', '%6.2f', '%5.1f', \n",
    "               '%5.1f', '%5.1f', '%5.1f', '%6.1f', '%5.1f', '%5.1f', \n",
    "               '%7.1f', '%7.1f', '%6.1f']\n",
    "    for key in metardata.keys():\n",
    "        if key in Debbie_stns:\n",
    "            fname = pjoin(outputPath, \"{0}_{1}.csv\".format(key, metarbasename[db]))\n",
    "            df = pd.DataFrame(metardata[key])\n",
    "            del df['index']\n",
    "            #dfdup = df.drop_duplicates(subset = ['dtDateTime'])\n",
    "            da = df.to_records(index=False)\n",
    "            np.savetxt(fname, da, fmt=metarfmt, delimiter=',') # NB, the numpy indexer is being written out?!?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-373bc02fdea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilelist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     arr = pd.read_csv(f, skiprows = 2, header=None, usecols = SYNOP_COLS, names = SYNOP_NAMES, \n\u001b[1;32m----> 7\u001b[1;33m                       dtype = SYNOP_DTYPE, na_values = -9999.0) #parse_dates = {'dtDateTime':[3, 4]}\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m     \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    937\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1508\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1509\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas\\parser.c:10415)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas\\parser.c:10691)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas\\parser.c:11728)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._convert_column_data (pandas\\parser.c:13162)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._convert_tokens (pandas\\parser.c:13807)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "synopbasename = \"IDY03000.2017032*.axf\"\n",
    "synopdata = {}\n",
    "\n",
    "filelist = glob(pjoin(inputPath, db))\n",
    "for f in filelist:\n",
    "    arr = pd.read_csv(f, skiprows = 2, header=None, usecols = SYNOP_COLS, names = SYNOP_NAMES, \n",
    "                      dtype = SYNOP_DTYPE, na_values = -9999.0, parse_dates = {'dtDateTime':[3, 4]})\n",
    "    print arr\n",
    "    cols = arr.columns.tolist()\n",
    "    cols[0], cols[1] = cols[1], cols[0]\n",
    "    arr = arr[cols]\n",
    "    arr = arr.to_records()\n",
    "    for i in range(len(arr)):\n",
    "        key = \"{0}\".format(arr[\"stnWMO\"][i])\n",
    "        if synopdata.has_key(key):\n",
    "            synopdata[key] = np.append(synopdata[key], arr[i])\n",
    "        else:\n",
    "            synopdata[key] = recarray(SYNOP_DTYPE)\n",
    "            synopdata[key] = arr[i]\n",
    "synopfmt = ['%s', '%s', '%s', '%s', '%6.2f', '%6.2f', '%5.1f', \n",
    "           '%5.1f', '%5.1f', '%5.1f', '%6.1f', '%5.1f', '%5.1f', \n",
    "           '%7.1f', '%7.1f', '%6.1f']\n",
    "for key in synopdata.keys():\n",
    "    if key in Debbie_stns:\n",
    "        fname = pjoin(outputPath, \"{0}_3000.csv\".format(key))\n",
    "        df = pd.DataFrame(synopdata[key])\n",
    "        #dfdup = df.drop_duplicates(subset = ['dtDateTime'])\n",
    "        da = df.to_records(index=False)\n",
    "        np.savetxt(fname, da, fmt=synopfmt, delimiter=',') # NB, the numpy indexer is being written out?!?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# synopbasename = \"IDY03000.2017032*.axf\"\n",
    "# synopdata = {}\n",
    "\n",
    "# filelist = glob(pjoin(inputPath, synopbasename))\n",
    "# for f in filelist:\n",
    "#     try:\n",
    "#         arr = np.genfromtxt(f, dtype=SYNOP_DTYPE, delimiter=',', skip_header=2,\n",
    "#                             skip_footer=1, usecols=SYNOP_COLS, names=SYNOP_NAMES,\n",
    "#                             autostrip=True, converters=SYNOP_CONV)\n",
    "#     except IndexError:\n",
    "#         print f\n",
    "#     if arr.size == 1:\n",
    "#         key = \"{0}\".format(arr[\"stnWMO\"])\n",
    "#         if synopdata.has_key(key):\n",
    "#             synopdata[key] = np.append(synopdata[key], arr)\n",
    "#         else:\n",
    "#             synopdata[key] = recarray(SYNOP_DTYPE)\n",
    "#             synopdata[key] = arr\n",
    "#     else:\n",
    "#         for i in range(len(arr)):\n",
    "#             key = \"{0}\".format(arr[\"stnWMO\"][i])\n",
    "#             if synopdata.has_key(key):\n",
    "#                 synopdata[key] = np.append(synopdata[key], arr[i])\n",
    "#             else:\n",
    "#                 synopdata[key] = recarray(SYNOP_DTYPE)\n",
    "#                 synopdata[key] = arr[i]\n",
    "# synopfmt = ['%s', '%s', '%s', '%s', '%s', '%6.2f', '%6.2f', '%5.1f', \n",
    "#             '%5.1f', '%d', '%s', '%d', '%6.1f', '%4.1f', '%4.1f']\n",
    "# for key in synopdata.keys():\n",
    "#     if key in Debbie_stns:\n",
    "#         fname = pjoin(outputPath, \"{0}_3000.csv\".format(key))\n",
    "#         try:\n",
    "#             df = pd.DataFrame(synopdata[key])\n",
    "#             dfdup = df.drop_duplicates(['dtDate', 'dtTime'])\n",
    "#             da = dfdup.to_records(index=False)\n",
    "#             np.savetxt(fname, da, fmt=synopfmt, delimiter=',')\n",
    "#         except IndexError:\n",
    "#             print key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def determineFormat(file):\n",
    "    '''\n",
    "    Uses the csv file name of the input file to determine which format (metar or synop), the file is, and therefore, \n",
    "    where the various variables are located within the file.\n",
    "    '''\n",
    "    name_parts = file.split('_')\n",
    "    name = name_parts[2]\n",
    "    name = name[:-4]\n",
    "    return name\n",
    "def getHeaders(file):\n",
    "    name = determineFormat(file)\n",
    "    if name == '3100' or name == '3101':\n",
    "        column_names = METAR_NAMES_MOD\n",
    "    elif name == '3000':\n",
    "        column_names = SYNOP_NAMES_MOD\n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plotcurve(file):\n",
    "    column_names = getHeaders(file)\n",
    "    data = pd.read_csv(file, header=None, names = column_names)\n",
    "    data['dtDateTime'] = pd.to_datetime(data['dtDateTime'])\n",
    "\n",
    "    # Set up the figure\n",
    "    fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(16,12), sharex=True)\n",
    "    \n",
    "#     if name == '3100' or name == '3101':  \n",
    "#         ax0.plot(data[7])# wind speed\n",
    "#         ax1.plot(data[10]) # Pressure\n",
    "#     elif name == '3000':\n",
    "#         ax0.plot(data[8])# wind speed\n",
    "#         ax1.plot(data[12]) # Pressure\n",
    "    ax0.plot(data['dtDateTime'], data['windspeed'])\n",
    "    ax1.plot(data['dtDateTime'], data['QNH'])\n",
    "    ax1.set_ylim((950,1020))\n",
    "    fig.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "avail_files = glob(outputPath + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = interactive(plotcurve, file=widgets.Dropdown(options=avail_files))\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in formatted csv files, and find the maximum gust for each file\n",
    "\n",
    "We will use this data to correct the local wind field from TCRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filelist = glob(outputPath + '\\*')\n",
    "max_gust_obs = pd.DataFrame()\n",
    "for f in filelist:\n",
    "    name = determineFormat(f)\n",
    "    if name == '3100': # or name == '3101':\n",
    "        data = pd.read_csv(f, names = METAR_NAMES_MOD)\n",
    "        max_gust = data['gust'].idxmax()\n",
    "        max_gust_obs = max_gust_obs.append(data.ix[max_gust], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "      <th>QNH</th>\n",
       "      <th>RF10min</th>\n",
       "      <th>RF9am</th>\n",
       "      <th>dewpt</th>\n",
       "      <th>dtDateTime</th>\n",
       "      <th>gust</th>\n",
       "      <th>stnCode</th>\n",
       "      <th>stnLat</th>\n",
       "      <th>stnLon</th>\n",
       "      <th>stnWMO</th>\n",
       "      <th>tempDB</th>\n",
       "      <th>vis</th>\n",
       "      <th>winddir</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>996.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>82.2</td>\n",
       "      <td>24.9</td>\n",
       "      <td>20170327  1728</td>\n",
       "      <td>50.0</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-21.17</td>\n",
       "      <td>149.18</td>\n",
       "      <td>95367.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>nan</td>\n",
       "      <td>130</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>20170328  0531</td>\n",
       "      <td>80.0</td>\n",
       "      <td>\"CR</td>\n",
       "      <td>-20.53</td>\n",
       "      <td>150.38</td>\n",
       "      <td>94371.0</td>\n",
       "      <td>26</td>\n",
       "      <td>nan</td>\n",
       "      <td>20</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900</td>\n",
       "      <td>969.2</td>\n",
       "      <td>2</td>\n",
       "      <td>76.2</td>\n",
       "      <td>24.5</td>\n",
       "      <td>20170328  0300</td>\n",
       "      <td>89.0</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-20.49</td>\n",
       "      <td>148.56</td>\n",
       "      <td>94365.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>nan</td>\n",
       "      <td>130</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200.0</td>\n",
       "      <td>968.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>20170328  0025</td>\n",
       "      <td>142.0</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-20.37</td>\n",
       "      <td>148.95</td>\n",
       "      <td>94368.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>310.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20170328  0430</td>\n",
       "      <td>44.0</td>\n",
       "      <td>\"AY</td>\n",
       "      <td>-19.62</td>\n",
       "      <td>147.38</td>\n",
       "      <td>95295.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>nan</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>997.7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20170328  0800</td>\n",
       "      <td>38.0</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-19.25</td>\n",
       "      <td>146.77</td>\n",
       "      <td>94294.0</td>\n",
       "      <td>29</td>\n",
       "      <td>nan</td>\n",
       "      <td>260</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avis     QNH RF10min  RF9am  dewpt       dtDateTime   gust stnCode  \\\n",
       "3     1300   996.5     1.8   82.2   24.9   20170327  1728   50.0     \"YB   \n",
       "0      nan     nan     nan    nan    nan   20170328  0531   80.0     \"CR   \n",
       "4      900   969.2       2   76.2   24.5   20170328  0300   89.0     \"YB   \n",
       "5    200.0   968.1     1.6   15.4   36.9   20170328  0025  142.0     \"YB   \n",
       "2      nan     nan       0    0.2   20.9   20170328  0430   44.0     \"AY   \n",
       "1    10000   997.7       0    3.2   21.6   20170328  0800   38.0     \"YB   \n",
       "\n",
       "   stnLat  stnLon   stnWMO tempDB      vis winddir  windspeed  \n",
       "3  -21.17  149.18  95367.0   25.4      nan     130       38.0  \n",
       "0  -20.53  150.38  94371.0     26      nan      20       23.0  \n",
       "4  -20.49  148.56  94365.0   24.7      nan     130       59.0  \n",
       "5  -20.37  148.95  94368.0   36.9      nan   310.0       97.0  \n",
       "2  -19.62  147.38  95295.0   28.6      nan     250       26.0  \n",
       "1  -19.25  146.77  94294.0     29      nan     260       22.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_gust_obs.sort_values('stnLat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert BoM wind field\n",
    "\n",
    "kts to m/s AND 3s gust to 0.2s gust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_gust_obs['gust'] = max_gust_obs['gust'] * 0.514444 # kts to m/s\n",
    "max_gust_obs['gust_conv'] = max_gust_obs['gust'] * (0.0006 * max_gust_obs['gust'] + 1.1105) # 3s to 0.2 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "      <th>QNH</th>\n",
       "      <th>RF10min</th>\n",
       "      <th>RF9am</th>\n",
       "      <th>dewpt</th>\n",
       "      <th>dtDateTime</th>\n",
       "      <th>gust</th>\n",
       "      <th>stnCode</th>\n",
       "      <th>stnLat</th>\n",
       "      <th>stnLon</th>\n",
       "      <th>stnWMO</th>\n",
       "      <th>tempDB</th>\n",
       "      <th>vis</th>\n",
       "      <th>winddir</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>gust_conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>20170328  0531</td>\n",
       "      <td>41.155520</td>\n",
       "      <td>\"CR</td>\n",
       "      <td>-20.53</td>\n",
       "      <td>150.38</td>\n",
       "      <td>94371.0</td>\n",
       "      <td>26</td>\n",
       "      <td>nan</td>\n",
       "      <td>20</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.719471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>997.7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20170328  0800</td>\n",
       "      <td>19.548872</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-19.25</td>\n",
       "      <td>146.77</td>\n",
       "      <td>94294.0</td>\n",
       "      <td>29</td>\n",
       "      <td>nan</td>\n",
       "      <td>260</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.938317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20170328  0430</td>\n",
       "      <td>22.635536</td>\n",
       "      <td>\"AY</td>\n",
       "      <td>-19.62</td>\n",
       "      <td>147.38</td>\n",
       "      <td>95295.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>nan</td>\n",
       "      <td>250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.444183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>996.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>82.2</td>\n",
       "      <td>24.9</td>\n",
       "      <td>20170327  1728</td>\n",
       "      <td>25.722200</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-21.17</td>\n",
       "      <td>149.18</td>\n",
       "      <td>95367.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>nan</td>\n",
       "      <td>130</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.961482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900</td>\n",
       "      <td>969.2</td>\n",
       "      <td>2</td>\n",
       "      <td>76.2</td>\n",
       "      <td>24.5</td>\n",
       "      <td>20170328  0300</td>\n",
       "      <td>45.785516</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-20.49</td>\n",
       "      <td>148.56</td>\n",
       "      <td>94365.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>nan</td>\n",
       "      <td>130</td>\n",
       "      <td>59.0</td>\n",
       "      <td>52.102604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200.0</td>\n",
       "      <td>968.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>20170328  0025</td>\n",
       "      <td>73.051048</td>\n",
       "      <td>\"YB</td>\n",
       "      <td>-20.37</td>\n",
       "      <td>148.95</td>\n",
       "      <td>94368.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>310.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>84.325062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avis     QNH RF10min  RF9am  dewpt       dtDateTime       gust stnCode  \\\n",
       "0      nan     nan     nan    nan    nan   20170328  0531  41.155520     \"CR   \n",
       "1    10000   997.7       0    3.2   21.6   20170328  0800  19.548872     \"YB   \n",
       "2      nan     nan       0    0.2   20.9   20170328  0430  22.635536     \"AY   \n",
       "3     1300   996.5     1.8   82.2   24.9   20170327  1728  25.722200     \"YB   \n",
       "4      900   969.2       2   76.2   24.5   20170328  0300  45.785516     \"YB   \n",
       "5    200.0   968.1     1.6   15.4   36.9   20170328  0025  73.051048     \"YB   \n",
       "\n",
       "   stnLat  stnLon   stnWMO tempDB      vis winddir  windspeed  gust_conv  \n",
       "0  -20.53  150.38  94371.0     26      nan      20       23.0  46.719471  \n",
       "1  -19.25  146.77  94294.0     29      nan     260       22.0  21.938317  \n",
       "2  -19.62  147.38  95295.0   28.6      nan     250       26.0  25.444183  \n",
       "3  -21.17  149.18  95367.0   25.4      nan     130       38.0  28.961482  \n",
       "4  -20.49  148.56  94365.0   24.7      nan     130       59.0  52.102604  \n",
       "5  -20.37  148.95  94368.0   36.9      nan   310.0       97.0  84.325062  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_gust_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputPath_obs = \"B:/CHARS/B_Wind/data/derived/tc/events/bsh132016/Observations/BoM_max_gust.csv\"\n",
    "max_gust_obs.to_csv(outputPath_obs, sep = ',', columns = ['dtDateTime', 'stnLat', 'stnLon', 'stnWMO', 'gust_conv'],\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
