{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC_Debbie_land_cover_classification\n",
    "\n",
    "Based on the notebook \"AA_photosynthetic_vegetation_median_Mackay_example.ipynb\" by Leo Lymburner.\n",
    "\n",
    "Written by Claire Krause, May 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Four AGDC datasets used in this classification**\n",
    "* surface reflectance (Landsat bands: red, green, blue, nir, swir1, swir2)\n",
    "* fractional cover - photosynthetic vegetation\n",
    "* fractional cover - bare soil\n",
    "* slope (derived from elevation)\n",
    "\n",
    "**Analysis time and extents**\n",
    "* time: '2015-01-01', '2015-05-01' - chosen as the approximate season prior to TC Debbie. Note that a change in the time period chosen will likely affect the classification scheme.\n",
    "* extent: 'lat': (-19.9, -20.97), 'lon': (147.97, 149.55)\n",
    "\n",
    "**Output categories**\n",
    "1. Forest\n",
    "2. Urban\n",
    "3. Open forest\n",
    "4. Crops/grassland\n",
    "5. Water\n",
    "6. Bare ground\n",
    "\n",
    "**Workflow**\n",
    "1. Each of the four datasets are read in separately to save memory. \n",
    "2. Bands are processed to generate surface reflectance and slope\n",
    "3. A time mean is created for the whole time extent\n",
    "4. Processed data are pickled and written out\n",
    "5. Once all the data are processed, the four picked datasets are read back into memory\n",
    "6. Each dataset is plotted with a categorical colour bar, and a histogram is created to show the spread of the data values to allow classification process to begin\n",
    "7. Classification is based on selected thresholds across the four datasets. This is based on subjective classification by the user. Values are tweaked to best differentiate known landscape features. Note that 'open forest' is used as a default category\n",
    "8. Classified Dataframe is written out to GeoTiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the analysis with fractional cover - photosynthetic vegetation (PV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "#%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define which pixel quality artefacts you want removed from the results\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load and mask Fractional Cover\n",
    "def load_multiple_masked_fc(platforms, query, bands):\n",
    "    datasets = []\n",
    "    for platform in platforms:\n",
    "        product_name = '{}_{}_albers'.format(platform, 'fc')\n",
    "        print ('Loading product: {}'.format(product_name))\n",
    "        # Load NBAR\n",
    "        ds = dc.load(product=product_name, measurements=bands, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(product_name))\n",
    "        crs = ds.crs\n",
    "        affine = ds.affine\n",
    "        # Load PQ Mask\n",
    "        mask_product = '{}_{}_albers'.format(platform, 'pq')\n",
    "        sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(mask_product))\n",
    "        cloud_free = make_mask(sensor_pq.pixelquality, **mask_components)\n",
    "        #cloud_free = make_mask(sensor_pq.pixelquality, ga_good_pixel=True)\n",
    "        print('Made cloud mask')\n",
    "        ds = ds.where(cloud_free) #.fillna(-999).astype('int16')\n",
    "        print('Masked out clouds')\n",
    "        ds['product'] = ('time', np.repeat(product_name, ds.time.size))\n",
    "        datasets.append(ds)\n",
    "\n",
    "    combined = xr.concat(datasets, dim='time')\n",
    "    combined = combined.isel(time=combined.time.argsort())  # sort along time dim\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product: ls8_fc_albers\n",
      "Loaded: ls8_fc_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 21, x: 7127, y: 5582)\n",
      "Coordinates:\n",
      "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
      "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
      "  * time     (time) datetime64[ns] 2015-01-08T00:04:53.500000 ...\n",
      "Data variables:\n",
      "    PV       (time, y, x) float64 nan nan nan nan nan nan nan nan nan nan ...\n",
      "    product  (time) <U13 'ls8_fc_albers' 'ls8_fc_albers' 'ls8_fc_albers' ...\n",
      "Attributes:\n",
      "    crs:      EPSG:3577\n",
      "CPU times: user 48.5 s, sys: 19.6 s, total: 1min 8s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "bands_of_interest = ['PV']\n",
    "platforms = ['ls8']\n",
    "query = {\n",
    "    'time': ('2015-01-01', '2015-05-01'), # Summer/approximate season of TC Debbie\n",
    "     'lat': (-19.9, -20.97),\n",
    "     'lon': (147.97, 149.55),\n",
    "    'resolution': (25, 25),\n",
    "        }\n",
    "fcDrill = load_multiple_masked_fc(platforms, query, bands_of_interest)\n",
    "print(fcDrill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (x: 7127, y: 5582)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
       "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
       "Data variables:\n",
       "    PV       (y, x) float64 36.0 42.0 43.0 45.0 47.0 46.0 42.0 44.0 40.0 ...\n",
       "    product  <U13 'ls8_fc_albers'\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean = fcDrill.min(dim='time', keep_attrs=True)\n",
    "all_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the final PV array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/PV.sav', 'wb') as f:\n",
    "        pickle.dump(all_mean, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear everything in memory and start again with bare soil\n",
    "\n",
    "Note that this command clear EVERYTHING, so need to reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "#%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define which pixel quality artefacts you want removed from the results\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load and mask Fractional Cover\n",
    "def load_multiple_masked_fc(platforms, query, bands):\n",
    "    datasets = []\n",
    "    for platform in platforms:\n",
    "        product_name = '{}_{}_albers'.format(platform, 'fc')\n",
    "        print ('Loading product: {}'.format(product_name))\n",
    "        # Load NBAR\n",
    "        ds = dc.load(product=product_name, measurements=bands, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(product_name))\n",
    "        crs = ds.crs\n",
    "        affine = ds.affine\n",
    "        # Load PQ Mask\n",
    "        mask_product = '{}_{}_albers'.format(platform, 'pq')\n",
    "        sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(mask_product))\n",
    "        cloud_free = make_mask(sensor_pq.pixelquality, **mask_components)\n",
    "        #cloud_free = make_mask(sensor_pq.pixelquality, ga_good_pixel=True)\n",
    "        print('Made cloud mask')\n",
    "        ds = ds.where(cloud_free) #.fillna(-999).astype('int16')\n",
    "        print('Masked out clouds')\n",
    "        ds['product'] = ('time', np.repeat(product_name, ds.time.size))\n",
    "        datasets.append(ds)\n",
    "\n",
    "    combined = xr.concat(datasets, dim='time')\n",
    "    combined = combined.isel(time=combined.time.argsort())  # sort along time dim\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process bare soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product: ls8_fc_albers\n",
      "Loaded: ls8_fc_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 21, x: 7127, y: 5582)\n",
      "Coordinates:\n",
      "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
      "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
      "  * time     (time) datetime64[ns] 2015-01-08T00:04:53.500000 ...\n",
      "Data variables:\n",
      "    BS       (time, y, x) float64 nan nan nan nan nan nan nan nan nan nan ...\n",
      "    product  (time) <U13 'ls8_fc_albers' 'ls8_fc_albers' 'ls8_fc_albers' ...\n",
      "Attributes:\n",
      "    crs:      EPSG:3577\n",
      "CPU times: user 48.3 s, sys: 18.5 s, total: 1min 6s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "bands_of_interest = ['BS']\n",
    "platforms = ['ls8']\n",
    "query = {\n",
    "    'time': ('2015-01-01', '2015-05-01'), # Summer/approximate season of TC Debbie\n",
    "     'lat': (-19.9, -20.97),\n",
    "     'lon': (147.97, 149.55),\n",
    "    'resolution': (25, 25),\n",
    "        }\n",
    "fcDrill = load_multiple_masked_fc(platforms, query, bands_of_interest)\n",
    "print(fcDrill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (x: 7127, y: 5582)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
       "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
       "Data variables:\n",
       "    BS       (y, x) float64 0.0 2.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 3.0 8.0 5.0 ...\n",
       "    product  <U13 'ls8_fc_albers'\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean = fcDrill.min(dim='time', keep_attrs=True)\n",
    "all_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the final BS array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/BS.sav', 'wb') as f:\n",
    "        pickle.dump(all_mean, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear everything in memory and start again with surface reflectance/albedo\n",
    "\n",
    "Note that this command clear EVERYTHING, so need to reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "#%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define which pixel quality artefacts you want removed from the results\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to load, mask and process data\n",
    "def load_multiple_masked_fc(platforms, query, bands):\n",
    "    for platform in platforms:\n",
    "        for band in bands:\n",
    "            product_name = '{}_{}_albers'.format(platform, 'nbar')\n",
    "            print ('Loading product: {}'.format(product_name))\n",
    "            # Load NBAR\n",
    "            ds = dc.load(product=product_name, measurements=[band], group_by='solar_day', **query)\n",
    "            print('Loaded: {}'.format(product_name))\n",
    "            crs = ds.crs\n",
    "            affine = ds.affine\n",
    "            # Load PQ Mask\n",
    "            mask_product = '{}_{}_albers'.format(platform, 'pq')\n",
    "            sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser, group_by='solar_day', **query)\n",
    "            print('Loaded: {}'.format(mask_product))\n",
    "            cloud_free = make_mask(sensor_pq.pixelquality, **mask_components)\n",
    "            #cloud_free = make_mask(sensor_pq.pixelquality, ga_good_pixel=True)\n",
    "            print('Made cloud mask')\n",
    "            ds = ds.where(cloud_free) #.fillna(-999).astype('int16')\\\n",
    "            print('Masked out clouds')\n",
    "            # Make just an average value for all time\n",
    "            ds = ds.mean(dim = 'time')        \n",
    "            try:\n",
    "                datasets\n",
    "            except:\n",
    "                datasets = ds\n",
    "            else:\n",
    "                datasets = xr.merge([datasets, ds])\n",
    "    print (datasets)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product: ls8_nbar_albers\n",
      "Loaded: ls8_nbar_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "Loading product: ls8_nbar_albers\n",
      "Loaded: ls8_nbar_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "Loading product: ls8_nbar_albers\n",
      "Loaded: ls8_nbar_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "Loading product: ls8_nbar_albers\n",
      "Loaded: ls8_nbar_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "Loading product: ls8_nbar_albers\n",
      "Loaded: ls8_nbar_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "Loading product: ls8_nbar_albers\n",
      "Loaded: ls8_nbar_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (x: 7127, y: 5582)\n",
      "Coordinates:\n",
      "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
      "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
      "Data variables:\n",
      "    blue     (y, x) float64 526.2 469.7 482.0 476.4 474.6 461.6 461.7 459.4 ...\n",
      "    green    (y, x) float64 744.0 694.9 720.9 708.4 698.7 684.9 690.3 674.9 ...\n",
      "    red      (y, x) float64 792.8 771.4 814.6 795.4 779.1 763.7 767.9 747.3 ...\n",
      "    nir      (y, x) float64 2.334e+03 2.373e+03 2.433e+03 2.424e+03 ...\n",
      "    swir1    (y, x) float64 2.536e+03 2.659e+03 2.782e+03 2.705e+03 ...\n",
      "    swir2    (y, x) float64 1.516e+03 1.61e+03 1.692e+03 1.631e+03 1.622e+03 ...\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (x: 7127, y: 5582)\n",
      "Coordinates:\n",
      "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
      "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
      "Data variables:\n",
      "    blue     (y, x) float64 526.2 469.7 482.0 476.4 474.6 461.6 461.7 459.4 ...\n",
      "    green    (y, x) float64 744.0 694.9 720.9 708.4 698.7 684.9 690.3 674.9 ...\n",
      "    red      (y, x) float64 792.8 771.4 814.6 795.4 779.1 763.7 767.9 747.3 ...\n",
      "    nir      (y, x) float64 2.334e+03 2.373e+03 2.433e+03 2.424e+03 ...\n",
      "    swir1    (y, x) float64 2.536e+03 2.659e+03 2.782e+03 2.705e+03 ...\n",
      "    swir2    (y, x) float64 1.516e+03 1.61e+03 1.692e+03 1.631e+03 1.622e+03 ...\n",
      "CPU times: user 5min 43s, sys: 1min 46s, total: 7min 29s\n",
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "bands_of_interest = ['blue',\n",
    "                     'green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1', \n",
    "                     'swir2'\n",
    "                     ]\n",
    "\n",
    "platforms = ['ls8']\n",
    "query = {\n",
    "        'time': ('2015-01-01', '2015-05-01'), # Summer/approximate season of TC Debbie\n",
    "        'lat': (-19.9, -20.97),\n",
    "        'lon': (147.97, 149.55),\n",
    "        'resolution': (25, 25)\n",
    "        }\n",
    "fcDrill = load_multiple_masked_fc(platforms, query, bands_of_interest)\n",
    "print(fcDrill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_together = fcDrill.red + fcDrill.blue + fcDrill.green + fcDrill.nir + fcDrill.swir1 + fcDrill.swir2\n",
    "add_together = add_together.to_dataset(name = 'reflectance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the final surface reflectance array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/add_all_bands.sav', 'wb') as f:\n",
    "        pickle.dump(add_together, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear everything in memory and start again with elevation\n",
    "\n",
    "Note that this command clear EVERYTHING, so need to reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "query = {'lat': (-19.9, -20.97),\n",
    "         'lon': (147.97, 149.55),\n",
    "         'output_crs': 'EPSG:3577', \n",
    "         'resolution': (-25, 25)\n",
    "        }\n",
    "\n",
    "elev = dc.load(product = 'srtm_dem1sv1_0', group_by='solar_day', **query)\n",
    "print (elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elev = elev.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.gradient(elev.dem_s, axis=(0,1))\n",
    "ns = abs(np.pi/2. - np.arctan(x))\n",
    "ew = (np.pi/2. - np.arctan(y))\n",
    "slope = np.maximum(ns, ew)\n",
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slope = xr.DataArray(slope, coords = {'y': elev.y, 'x': elev.x})\n",
    "slope = slope.to_dataset(name = 'slope')\n",
    "slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the final slope array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/slope.sav', 'wb') as f:\n",
    "        pickle.dump(slope, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull all our datasets back in for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_file = gzip.open('/g/data/r78/cek156/PV.sav', 'rb')\n",
    "PV = pickle.load(PV_file)\n",
    "\n",
    "BS_file = gzip.open('/g/data/r78/cek156/BS.sav', 'rb')\n",
    "BS = pickle.load(BS_file)\n",
    "\n",
    "albedo_file = gzip.open('/g/data/r78/cek156/add_all_bands.sav', 'rb')\n",
    "albedo = pickle.load(albedo_file)\n",
    "\n",
    "slope_file = gzip.open('/g/data/r78/cek156/slope.sav', 'rb')\n",
    "slope = pickle.load(slope_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albedo, PV, slope, BS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot up data to begin to determine cut off values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fractional cover - photosynthetic vegetation (PV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', '#ffcc66','#ffffcc'  , '#2eb82e', '#009933' , '#006600', 'black'])\n",
    "pv_bounds = [0,1, 10, 20, 30, 50, 65, 75, 100]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "PV.PV.plot.imshow(cmap = pv_cmap, norm = pv_norm, vmin = 0, vmax = 25000)\n",
    "\n",
    "fig = plt.figure()\n",
    "PV.PV.plot.hist(bins = 100)\n",
    "plt.xlim([0,100])\n",
    "plt.ylim([0, 1000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fractional cover - bare soil (BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', '#ffcc66','#ffffcc'  , '#2eb82e', '#009933' ,'black'])\n",
    "pv_bounds = [0, 1, 5, 10, 15, 20, 30]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "BS.BS.plot.imshow(cmap = pv_cmap, norm = pv_norm, vmin = 0, vmax = 25000)\n",
    "\n",
    "fig = plt.figure()\n",
    "BS.BS.plot.hist(bins = 100)\n",
    "plt.xlim([0,60])\n",
    "plt.ylim([0, 2000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', 'cyan', '#ffcc66', '#ffffcc', 'black'])\n",
    "pv_bounds = [0, 3500, 6000, 8000, 10000, 12000]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "albedo.reflectance.plot.imshow(cmap = pv_cmap, norm = pv_norm, vmin = 0, vmax = 12000)\n",
    "\n",
    "fig = plt.figure()\n",
    "albedo.reflectance.plot.hist(bins = 100)\n",
    "plt.xlim([0,15000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', '#ffcc66','#ffffcc'  , '#2eb82e', '#009933' , '#006600', 'black'])\n",
    "pv_bounds = [0, 1, 1.56, 1.58, 2.5, 3]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "slope.slope.plot.imshow(cmap = pv_cmap, norm = pv_norm, vmin = 0, vmax = 3)\n",
    "\n",
    "fig = plt.figure()\n",
    "slope.slope.plot.hist(bins = 32)\n",
    "plt.xlim([0,3.2])\n",
    "plt.ylim([0, 2000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category | Classifier | Mz\n",
    "\n",
    "* Forest | PV >= 75\t| 774\n",
    "* Urban\t| BS >=30 & PV >=7 | 806\n",
    "* Open forest | what's left over |898\n",
    "* Crops/grassland |PV >=30 & PV <85 & slope >1.58 & slope <=2.5 | 949\n",
    "* Water | slope >= 1.56 & slope <= 1.58\t| 1000\n",
    "* Bare ground | reflectance >=9000 & PV <=50 & PV >=1 | 1063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with all of the data in it\n",
    "all_data = xr.merge([albedo.reflectance, PV.PV, slope.slope, BS.BS])\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = np.empty((len(all_data.y), len(all_data.x)))\n",
    "classified[:] = np.nan\n",
    "classified = xr.DataArray(classified, coords = [all_data.y, all_data.x], dims = ['y', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classify forest\n",
    "x = all_data.PV.where(all_data['PV'] >= 75)\n",
    "forest = x * 0 + 774\n",
    "classified = classified.combine_first(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify urban\n",
    "x = all_data.BS.where((all_data['BS'] >= 30) & (all_data['PV'] >= 7))\n",
    "urban = x * 0 + 806\n",
    "classified = classified.combine_first(urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bare soil\n",
    "x = all_data.PV.where((all_data['reflectance'] >= 9000) & (all_data['PV'] <= 50) & (all_data['PV'] >=1))\n",
    "bare = x * 0 + 1063\n",
    "classified = classified.combine_first(bare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify crops\n",
    "x = all_data.PV.where((all_data['PV'] >= 30) & (all_data['PV'] < 85) \n",
    "                      & (all_data['slope'] > 1.58) & (all_data['slope'] <= 2.5))\n",
    "crops = x * 0 + 949\n",
    "classified = classified.combine_first(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify water\n",
    "x = all_data.slope.where((all_data['slope'] >= 1.56) & (all_data['slope'] <= 1.58))\n",
    "water = x * 0 + 1000\n",
    "classified = classified.combine_first(water)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will assume that everything that has not already been classified is open forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify open forest\n",
    "open_forest = all_data.PV * 0 + 898\n",
    "open_forest\n",
    "classified = classified.combine_first(open_forest)\n",
    "\n",
    "# x = all_data.PV.where((all_data['PV'] >= 30) & (all_data['PV'] < 85) & (all_data['reflectance'] >= 9000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot up the classified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cmap = mpl.colors.ListedColormap(['#006600', 'brown', '#2eb82e','#ffcc66' , 'blue', 'grey'])\n",
    "class_bounds = [774, 806, 898, 949, 1000, 1063, 1064]\n",
    "class_norm = mpl.colors.BoundaryNorm(class_bounds, class_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "cax = classified.plot.imshow(cmap = class_cmap, norm = class_norm, vmin = 0, vmax = 1064, add_colorbar = False)\n",
    "cbar = fig.colorbar(cax, ticks= class_bounds)\n",
    "cbar.ax.set_yticklabels(['forest', 'urban', 'open forest', 'crops/grassland', 'water', 'bare'])\n",
    "\n",
    "# fig = plt.figure()\n",
    "# slope.slope.plot.hist(bins = 32)\n",
    "# plt.xlim([0,3.2])\n",
    "# plt.ylim([0, 2000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the classified file to GeoTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_geotiff(filename, dataset, time_index=None, profile_override=None):\n",
    "    \"\"\"\n",
    "    Function below is from https://github.com/data-cube/agdc-v2/blob/develop/datacube/helpers.py\n",
    "    Write an xarray dataset to a geotiff\n",
    "    :attr bands: ordered list of dataset names\n",
    "    :attr time_index: time index to write to file\n",
    "    :attr dataset: xarray dataset containing multiple bands to write to file\n",
    "    :attr profile_override: option dict, overrides rasterio file creation options.\n",
    "    \"\"\"\n",
    "    DEFAULT_PROFILE = {\n",
    "    'blockxsize': 128,\n",
    "    'blockysize': 128,\n",
    "    'compress': 'lzw',\n",
    "    'driver': 'GTiff',\n",
    "    'interleave': 'band',\n",
    "    'nodata': 0.0,\n",
    "    'photometric': 'RGBA',\n",
    "    'tiled': True}\n",
    "\n",
    "    profile_override = profile_override or {}\n",
    "\n",
    "    dtypes = {val.dtype for val in dataset.data_vars.values()}\n",
    "    assert len(dtypes) == 1  # Check for multiple dtypes\n",
    "\n",
    "    profile = DEFAULT_PROFILE.copy()\n",
    "    profile.update({\n",
    "        'width': dataset.dims['x'],\n",
    "        'height': dataset.dims['y'],\n",
    "        'affine': dataset.affine,\n",
    "        #'crs': dataset.crs.crs_str,\n",
    "        'crs': dataset.crs,\n",
    "        'count': len(dataset.data_vars),\n",
    "        'dtype': str(dtypes.pop())\n",
    "    })\n",
    "    profile.update(profile_override)\n",
    "\n",
    "    with rasterio.open(filename, 'w', **profile) as dest:\n",
    "        for bandnum, data in enumerate(dataset.data_vars.values(), start=1):\n",
    "            #dest.write(data.isel(time=time_index).data, bandnum)\n",
    "            dest.write(data, bandnum)\n",
    "            print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write the files out into a tif file for viewing in GIS\n",
    "\n",
    "outfile = '/g/data/r78/cek156/classified_TCDebbie.tiff'\n",
    "write_geotiff(outfile, slop_xr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
