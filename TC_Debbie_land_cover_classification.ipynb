{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC_Debbie_land_cover_classification\n",
    "\n",
    "Based on the notebook \"AA_photosynthetic_vegetation_median_Mackay_example.ipynb\" by Leo Lymburner.\n",
    "\n",
    "Written by Claire Krause, May 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Four AGDC datasets used in this classification**\n",
    "* surface reflectance (Landsat bands: red, green, blue)\n",
    "* fractional cover - photosynthetic vegetation\n",
    "* fractional cover - bare soil\n",
    "* slope (derived from elevation)\n",
    "\n",
    "**Analysis time and extents**\n",
    "* time: '2015-01-01', '2015-05-01' - chosen as the approximate season prior to TC Debbie. Note that a change in the time period chosen will likely affect the classification scheme.\n",
    "* extent: 'lat': (-19.9, -20.97), 'lon': (147.97, 149.55)\n",
    "\n",
    "**Output categories**\n",
    "1. Forest\n",
    "2. Urban\n",
    "3. Open forest\n",
    "4. Crops/grassland\n",
    "5. Water\n",
    "6. Bare ground\n",
    "\n",
    "**Workflow**\n",
    "1. Each of the four datasets are read in separately to save memory. \n",
    "2. Bands are processed to generate surface reflectance and slope\n",
    "3. A time mean is created for the whole time extent\n",
    "4. Processed data are pickled and written out\n",
    "5. Once all the data are processed, the four picked datasets are read back into memory\n",
    "6. Each dataset is plotted with a categorical colour bar, and a histogram is created to show the spread of the data values to allow classification process to begin\n",
    "7. Classification is based on selected thresholds across the four datasets. This is based on subjective classification by the user. Values are tweaked to best differentiate known landscape features. Note that 'open forest' is used as a default category\n",
    "8. Classified Dataframe is written out to GeoTiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the analysis with fractional cover - photosynthetic vegetation (PV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "#%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define which pixel quality artefacts you want removed from the results\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load and mask Fractional Cover\n",
    "def load_multiple_masked_fc(platforms, query, bands):\n",
    "    datasets = []\n",
    "    for platform in platforms:\n",
    "        product_name = '{}_{}_albers'.format(platform, 'fc')\n",
    "        print ('Loading product: {}'.format(product_name))\n",
    "        # Load NBAR\n",
    "        ds = dc.load(product=product_name, measurements=bands, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(product_name))\n",
    "        crs = ds.crs\n",
    "        affine = ds.affine\n",
    "        # Load PQ Mask\n",
    "        mask_product = '{}_{}_albers'.format(platform, 'pq')\n",
    "        sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(mask_product))\n",
    "        cloud_free = make_mask(sensor_pq.pixelquality, **mask_components)\n",
    "        #cloud_free = make_mask(sensor_pq.pixelquality, ga_good_pixel=True)\n",
    "        print('Made cloud mask')\n",
    "        ds = ds.where(cloud_free) #.fillna(-999).astype('int16')\n",
    "        print('Masked out clouds')\n",
    "        ds['product'] = ('time', np.repeat(product_name, ds.time.size))\n",
    "        datasets.append(ds)\n",
    "\n",
    "    combined = xr.concat(datasets, dim='time')\n",
    "    combined = combined.isel(time=combined.time.argsort())  # sort along time dim\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product: ls8_fc_albers\n",
      "Loaded: ls8_fc_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 21, x: 7127, y: 5582)\n",
      "Coordinates:\n",
      "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
      "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
      "  * time     (time) datetime64[ns] 2015-01-08T00:04:53.500000 ...\n",
      "Data variables:\n",
      "    PV       (time, y, x) float64 nan nan nan nan nan nan nan nan nan nan ...\n",
      "    product  (time) <U13 'ls8_fc_albers' 'ls8_fc_albers' 'ls8_fc_albers' ...\n",
      "Attributes:\n",
      "    crs:      EPSG:3577\n",
      "CPU times: user 47.8 s, sys: 35.4 s, total: 1min 23s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "bands_of_interest = ['PV']\n",
    "platforms = ['ls8']\n",
    "query = {\n",
    "    'time': ('2015-01-01', '2015-05-01'), # Summer/approximate season of TC Debbie\n",
    "     'lat': (-19.9, -20.97),\n",
    "     'lon': (147.97, 149.55),\n",
    "    'resolution': (25, 25),\n",
    "        }\n",
    "fcDrill = load_multiple_masked_fc(platforms, query, bands_of_interest)\n",
    "print(fcDrill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (x: 7127, y: 5582)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
       "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
       "Data variables:\n",
       "    PV       (y, x) float64 36.0 42.0 43.0 45.0 47.0 46.0 42.0 44.0 40.0 ...\n",
       "    product  <U13 'ls8_fc_albers'\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean = fcDrill.min(dim='time', keep_attrs=True)\n",
    "all_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the final PV array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/PV.sav', 'wb') as f:\n",
    "        pickle.dump(all_mean, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear everything in memory and start again with bare soil\n",
    "\n",
    "Note that this command clear EVERYTHING, so need to reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "#%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define which pixel quality artefacts you want removed from the results\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load and mask Fractional Cover\n",
    "def load_multiple_masked_fc(platforms, query, bands):\n",
    "    datasets = []\n",
    "    for platform in platforms:\n",
    "        product_name = '{}_{}_albers'.format(platform, 'fc')\n",
    "        print ('Loading product: {}'.format(product_name))\n",
    "        # Load NBAR\n",
    "        ds = dc.load(product=product_name, measurements=bands, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(product_name))\n",
    "        crs = ds.crs\n",
    "        affine = ds.affine\n",
    "        # Load PQ Mask\n",
    "        mask_product = '{}_{}_albers'.format(platform, 'pq')\n",
    "        sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser, group_by='solar_day', **query)\n",
    "        print('Loaded: {}'.format(mask_product))\n",
    "        cloud_free = make_mask(sensor_pq.pixelquality, **mask_components)\n",
    "        #cloud_free = make_mask(sensor_pq.pixelquality, ga_good_pixel=True)\n",
    "        print('Made cloud mask')\n",
    "        ds = ds.where(cloud_free) #.fillna(-999).astype('int16')\n",
    "        print('Masked out clouds')\n",
    "        ds['product'] = ('time', np.repeat(product_name, ds.time.size))\n",
    "        datasets.append(ds)\n",
    "\n",
    "    combined = xr.concat(datasets, dim='time')\n",
    "    combined = combined.isel(time=combined.time.argsort())  # sort along time dim\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process bare soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product: ls8_fc_albers\n",
      "Loaded: ls8_fc_albers\n",
      "Loaded: ls8_pq_albers\n",
      "Made cloud mask\n",
      "Masked out clouds\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 21, x: 7127, y: 5582)\n",
      "Coordinates:\n",
      "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
      "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
      "  * time     (time) datetime64[ns] 2015-01-08T00:04:53.500000 ...\n",
      "Data variables:\n",
      "    BS       (time, y, x) float64 nan nan nan nan nan nan nan nan nan nan ...\n",
      "    product  (time) <U13 'ls8_fc_albers' 'ls8_fc_albers' 'ls8_fc_albers' ...\n",
      "Attributes:\n",
      "    crs:      EPSG:3577\n",
      "CPU times: user 48.4 s, sys: 24.7 s, total: 1min 13s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "bands_of_interest = ['BS']\n",
    "platforms = ['ls8']\n",
    "query = {\n",
    "    'time': ('2015-01-01', '2015-05-01'), # Summer/approximate season of TC Debbie\n",
    "     'lat': (-19.9, -20.97),\n",
    "     'lon': (147.97, 149.55),\n",
    "    'resolution': (25, 25),\n",
    "        }\n",
    "fcDrill = load_multiple_masked_fc(platforms, query, bands_of_interest)\n",
    "print(fcDrill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (x: 7127, y: 5582)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.376e+06 -2.376e+06 -2.376e+06 -2.376e+06 ...\n",
       "  * x        (x) float64 1.646e+06 1.646e+06 1.646e+06 1.646e+06 1.646e+06 ...\n",
       "Data variables:\n",
       "    BS       (y, x) float64 0.0 2.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 3.0 8.0 5.0 ...\n",
       "    product  <U13 'ls8_fc_albers'\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean = fcDrill.min(dim='time', keep_attrs=True)\n",
    "all_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the final BS array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/BS.sav', 'wb') as f:\n",
    "        pickle.dump(all_mean, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear everything in memory and start again with surface reflectance/albedo\n",
    "\n",
    "Note that this command clear EVERYTHING, so need to reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "#%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define which pixel quality artefacts you want removed from the results\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to load, mask and process data\n",
    "def load_multiple_masked_fc(platforms, query, bands):\n",
    "    for platform in platforms:\n",
    "        for band in bands:\n",
    "            product_name = '{}_{}_albers'.format(platform, 'nbar')\n",
    "            print ('Loading product: {}'.format(product_name))\n",
    "            # Load NBAR\n",
    "            ds = dc.load(product=product_name, measurements=[band], group_by='solar_day', **query)\n",
    "            print('Loaded: {}'.format(product_name))\n",
    "            crs = ds.crs\n",
    "            affine = ds.affine\n",
    "            # Load PQ Mask\n",
    "            mask_product = '{}_{}_albers'.format(platform, 'pq')\n",
    "            sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser, group_by='solar_day', **query)\n",
    "            print('Loaded: {}'.format(mask_product))\n",
    "            cloud_free = make_mask(sensor_pq.pixelquality, **mask_components)\n",
    "            #cloud_free = make_mask(sensor_pq.pixelquality, ga_good_pixel=True)\n",
    "            print('Made cloud mask')\n",
    "            ds = ds.where(cloud_free) #.fillna(-999).astype('int16')\\\n",
    "            print('Masked out clouds')\n",
    "            # Make just an average value for all time\n",
    "            ds = ds.mean(dim = 'time')        \n",
    "            try:\n",
    "                datasets\n",
    "            except:\n",
    "                datasets = ds\n",
    "            else:\n",
    "                datasets = xr.merge([datasets, ds])\n",
    "    print (datasets)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "bands_of_interest = ['blue',\n",
    "                     'green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1',\n",
    "                     'swir2']\n",
    "\n",
    "platforms = ['ls8']\n",
    "query = {\n",
    "        'time': ('2015-01-01', '2015-05-01'), # Summer/approximate season of TC Debbie\n",
    "        'lat': (-19.9, -20.97),\n",
    "        'lon': (147.97, 149.55),\n",
    "        'resolution': (25, 25)\n",
    "        }\n",
    "fcDrill = load_multiple_masked_fc(platforms, query, bands_of_interest)\n",
    "print(fcDrill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_together = fcDrill.red + fcDrill.blue + fcDrill.green + fcDrill.nir + fcDrill.swir1 + fcDrill.swir2\n",
    "add_together = add_together.to_dataset(name = 'reflectance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the final surface reflectance array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/add_all_bands.sav', 'wb') as f:\n",
    "        pickle.dump(add_together, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear everything in memory and start again with elevation\n",
    "\n",
    "Note that this command clear EVERYTHING, so need to reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dc = datacube.Datacube(app='FC-App')#, config=dbconfig)\n",
    "\n",
    "query = {'lat': (-19.9, -20.97),\n",
    "         'lon': (147.97, 149.55),\n",
    "         'output_crs': 'EPSG:3577', \n",
    "         'resolution': (-25, 25)\n",
    "        }\n",
    "\n",
    "elev = dc.load(product = 'srtm_dem1sv1_0', group_by='solar_day', **query)\n",
    "print (elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elev = elev.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.gradient(elev.dem_s, axis=(0,1))\n",
    "ns = abs(np.pi/2. - np.arctan(x))\n",
    "ew = (np.pi/2. - np.arctan(y))\n",
    "slope = np.maximum(ns, ew)\n",
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slope = xr.DataArray(slope, coords = {'y': elev.y, 'x': elev.x})\n",
    "slope = slope.to_dataset(name = 'slope')\n",
    "slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the final slope array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "with gzip.open('/g/data/r78/cek156/slope.sav', 'wb') as f:\n",
    "        pickle.dump(slope, f,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull all our datasets back in for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%pylab notebook\n",
    "import ipywidgets as widgets\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.api import make_mask\n",
    "import pickle, gzip\n",
    "import folium\n",
    "from IPython.display import display\n",
    "import scipy.ndimage\n",
    "import netCDF4\n",
    "from osgeo.osr import SpatialReference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_file = gzip.open('/g/data/r78/cek156/PV.sav', 'rb')\n",
    "PV = pickle.load(PV_file)\n",
    "\n",
    "BS_file = gzip.open('/g/data/r78/cek156/BS.sav', 'rb')\n",
    "BS = pickle.load(BS_file)\n",
    "\n",
    "albedo_file = gzip.open('/g/data/r78/cek156/add_all_bands.sav', 'rb')\n",
    "albedo = pickle.load(albedo_file)\n",
    "\n",
    "slope_file = gzip.open('/g/data/r78/cek156/slope.sav', 'rb')\n",
    "slope = pickle.load(slope_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albedo, PV, slope, BS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot up data to begin to determine cut off values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fractional cover - photosynthetic vegetation (PV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', '#ffcc66','#ffffcc'  , '#2eb82e', '#009933' , '#006600', 'black'])\n",
    "pv_bounds = [0,1, 10, 20, 30, 50, 65, 75, 100]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "PV.PV.plot.imshow(cmap = pv_cmap, norm = pv_norm, vmin = 0, vmax = 25000)\n",
    "\n",
    "fig = plt.figure()\n",
    "PV.PV.plot.hist(bins = 100)\n",
    "plt.xlim([0,100])\n",
    "plt.ylim([0, 1000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fractional cover - bare soil (BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', '#ffcc66','#ffffcc'  , '#2eb82e', '#009933' ,'black'])\n",
    "pv_bounds = [0, 1, 5, 10, 15, 20, 30]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "BS.BS.plot.imshow(cmap = pv_cmap, norm = pv_norm, vmin = 0, vmax = 25000)\n",
    "\n",
    "fig = plt.figure()\n",
    "BS.BS.plot.hist(bins = 100)\n",
    "plt.xlim([0,60])\n",
    "plt.ylim([0, 2000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', 'cyan', '#ffcc66', '#ffffcc', 'black'])\n",
    "pv_bounds = [6000, 6500, 7000, 7500, 8000]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "albedo.reflectance.plot.imshow(cmap = 'jet', vmin = 0, vmax = 4000)#norm = pv_norm, \n",
    "\n",
    "fig = plt.figure()\n",
    "albedo.reflectance.plot.hist(bins = 100)\n",
    "plt.xlim([0,15000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_cmap = mpl.colors.ListedColormap(['blue', 'brown', '#ffcc66','#ffffcc'  , '#2eb82e', '#009933' , '#006600', 'black'])\n",
    "pv_bounds = [0, 1, 1.56, 1.58, 2.5, 3]\n",
    "pv_norm = mpl.colors.BoundaryNorm(pv_bounds, pv_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "slope.slope.plot.imshow(cmap = pv_cmap, norm = pv_norm, vmin = 0, vmax = 3)\n",
    "\n",
    "fig = plt.figure()\n",
    "slope.slope.plot.hist(bins = 32)\n",
    "plt.xlim([0,3.2])\n",
    "plt.ylim([0, 2000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category | Classifier | Mz\n",
    "\n",
    "* Water | slope >= 1.56 & slope <= 1.58\t| 1000\n",
    "* Forest | reflectance <=6900\t| 774\n",
    "* Urban\t| BS >=30 & PV >=7 | 806\n",
    "* Open forest | what's left over |898\n",
    "* Crops/grassland |PV >=30 & PV <85 & slope >1.58 & slope <=2.5 | 949\n",
    "* Bare ground | reflectance >=9000 & PV <=50 & PV >=1 | 1063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with all of the data in it\n",
    "all_data = xr.merge([albedo.reflectance, PV.PV, slope.slope, BS.BS])\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = np.empty((len(all_data.y), len(all_data.x)))\n",
    "classified[:] = np.nan\n",
    "classified = xr.DataArray(classified, coords = [all_data.y, all_data.x], dims = ['y', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify water\n",
    "x = all_data.slope.where((all_data['slope'] >= 1.56) & (all_data['slope'] <= 1.58) & (all_data['PV'] <= 1))\n",
    "water = x * 0 + 1000\n",
    "classified = classified.combine_first(water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classify forest\n",
    "# NB. Forest classification needs to happen after water, or else this condition picks up water too.\n",
    "x = all_data.PV.where(all_data['reflectance'] <=6900)\n",
    "forest = x * 0 + 774\n",
    "classified = classified.combine_first(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify urban\n",
    "x = all_data.BS.where((all_data['BS'] >= 30) & (all_data['PV'] >= 7))\n",
    "urban = x * 0 + 806\n",
    "classified = classified.combine_first(urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bare soil\n",
    "x = all_data.PV.where((all_data['reflectance'] >= 9000) & (all_data['PV'] <= 50) & (all_data['PV'] >=1))\n",
    "bare = x * 0 + 1063\n",
    "classified = classified.combine_first(bare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify crops\n",
    "x = all_data.PV.where((all_data['PV'] >= 30) & (all_data['PV'] < 85) \n",
    "                      & (all_data['slope'] > 1.58) & (all_data['slope'] <= 2.5))\n",
    "crops = x * 0 + 949\n",
    "classified = classified.combine_first(crops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will assume that everything that has not already been classified is open forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify open forest\n",
    "open_forest = all_data.PV * 0 + 898\n",
    "open_forest\n",
    "classified = classified.combine_first(open_forest)\n",
    "\n",
    "# x = all_data.PV.where((all_data['PV'] >= 30) & (all_data['PV'] < 85) & (all_data['reflectance'] >= 9000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot up the classified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cmap = mpl.colors.ListedColormap(['#006600', 'brown', '#2eb82e','#ffcc66' , 'blue', 'lightgrey'])\n",
    "class_bounds = [774, 806, 898, 949, 1000, 1063, 1064]\n",
    "class_norm = mpl.colors.BoundaryNorm(class_bounds, class_cmap.N)\n",
    "\n",
    "fig = plt.figure()\n",
    "cax = classified.plot.imshow(cmap = class_cmap, norm = class_norm, vmin = 0, vmax = 1064, add_colorbar = False)\n",
    "cbar = fig.colorbar(cax, ticks= class_bounds)\n",
    "cbar.ax.set_yticklabels(['forest', 'urban', 'open forest', 'crops/grassland', 'water', 'bare'])\n",
    "\n",
    "# fig = plt.figure()\n",
    "# slope.slope.plot.hist(bins = 32)\n",
    "# plt.xlim([0,3.2])\n",
    "# plt.ylim([0, 2000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to dataset so we can name the array variable\n",
    "classified = classified.to_dataset(name='classified')\n",
    "\n",
    "# Write out to netcdf\n",
    "outfile = '/g/data/r78/cek156/classified_TCDebbie.nc'\n",
    "classified.to_netcdf(path = outfile, mode = 'w')\n",
    "\n",
    "# Get the WKT for EPSG:3577 (AGDC projection) \n",
    "spatial_ref_object = SpatialReference()\n",
    "spatial_ref_object.ImportFromEPSG(3577)\n",
    "spatial_ref = spatial_ref_object.ExportToWkt()\n",
    "\n",
    "# Add it back into the netcdf file\n",
    "def fix_crs(nc_path):\n",
    "    nc_dataset = netCDF4.Dataset(nc_path, 'r+')\n",
    "    crs = nc_dataset.createVariable('crs', str)\n",
    "    x = nc_dataset.variables['x']\n",
    "    y = nc_dataset.variables['y']\n",
    "    x_pixel_size = float(max(x[:]) - min(x[:])) / (len(x) - 1)\n",
    "    y_pixel_size = float(min(y[:]) - max(y[:])) / (len(y) - 1) # Negative\n",
    "    GeoTransform = [min(x[:]) - x_pixel_size / 2.0, x_pixel_size, 0, max(y[:]) + y_pixel_size / 2.0, 0, y_pixel_size]\n",
    "    crs.spatial_ref = spatial_ref\n",
    "    crs.GeoTransform = ' '.join([str(n) for n in GeoTransform])\n",
    "    nc_dataset.close()\n",
    "\n",
    "fix_crs(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and plot up classified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = xr.open_dataset('/g/data/r78/cek156/classified_TCDebbie.nc')\n",
    "classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
